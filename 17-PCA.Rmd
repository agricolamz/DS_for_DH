---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Методы уменьшения размерностей

```{r, message=FALSE}
library(tidyverse)
```

```{r, include=FALSE}
theme_set(theme_bw())
```

Методы уменьшения размерностей -- это эксплораторные методы, которые позволяет использовать меньше переменных для того, чтобы найти связи в данных и связи между переменными. Немножко жаргона: размерность здесь является прямым аналогом размерности в описании физических объектов (например, 2-ухмерное, 3-ехмерное, 4-ехмерное и т. д. пространство). Важно понимать, что каждая переменная в любом датасете можно воспринимать как отдельную размерность, так что каждая строчка в датасете `mtcars` -- объект в `r ncol(mtcars)`-мерном пространстве просто потому что в этом датасете `r ncol(mtcars)` переменных.

## Визуализация многомерных пространств

Визуализация многомерного пространства --- дело сложное. Когда переменных не так уж и много, то в целом данную задачу можно решить используя разные трюки:

* много диаграмм рассеяния
```{r ggally, message = FALSE, cache=TRUE, fig.width=8, fig.height=8}
library(GGally)
ggpairs(mtcars)
```

* радиальная диаграмма (радар, паук)

```{r}
mtcars %>% 
  mutate(car_names = rownames(mtcars)) %>% 
  pivot_longer(names_to = "variables", values_to = "values", mpg:carb) %>%
  mutate(variables = factor(variables, levels = colnames(mtcars))) %>%   
  ggplot(aes(variables, values, color = car_names, group = car_names))+
  geom_point()+
  geom_polygon(fill = NA)+
  ggproto("CordRadar", CoordPolar, theta = "x", r = "x", start = 0, direction = 1, is_linear = function(coord) TRUE)
```

Не очень видно. Давайте нормализуем переменные:

```{r}
mtcars %>% 
  mutate_all(scale) %>% 
  mutate(car_names = rownames(mtcars)) %>% 
  pivot_longer(names_to = "variables", values_to = "values", mpg:carb) %>% 
  mutate(variables = factor(variables, levels = colnames(mtcars))) %>%   
  ggplot(aes(variables, values, color = car_names, group = car_names))+
  geom_point()+
  geom_polygon(fill = NA)+
  ggproto("CordRadar", CoordPolar, theta = "x", r = "x", start = 0, direction = 1, is_linear = function(coord) TRUE)
```

Все равно не очень хорошо видно, давайте сделаем фасетизацию:

```{r, fig.width=12, fig.height=12}
mtcars %>% 
  mutate_all(scale) %>% 
  mutate(car_names = rownames(mtcars)) %>% 
  pivot_longer(names_to = "variables", values_to = "values", mpg:carb) %>% 
  mutate(variables = factor(variables, levels = colnames(mtcars))) %>%   
  ggplot(aes(variables, values, group = car_names, color = car_names))+
  geom_point(show.legend = FALSE)+
  geom_polygon(fill = NA, show.legend = FALSE)+
  facet_wrap(~car_names)+
  ggproto("CordRadar", CoordPolar, theta = "x", r = "x", start = 0, direction = 1, is_linear = function(coord) TRUE)
```


## Простой пример: из двумерного пространства в одномерное пространство
Мы уже рассматривали связь между количество слов в рассказе и количеством слов *и* в рассказах М. Зощенко:

```{r, echo=FALSE, fig.height=7, message=FALSE}
read_tsv("https://github.com/agricolamz/DS_for_DH/raw/master/data/tidy_zoshenko.csv") %>% 
  filter(word == "и",
         n_words < 1500) %>% 
  mutate(titles = str_to_sentence(titles)) %>% 
  distinct() ->
  zo

library(ggrepel)

zo %>%   
  ggplot(aes(n_words, n, label = titles))+
  geom_point()+
  geom_text_repel()+
  labs(x = "количество слов в рассказе",
       y = "количество и")
```

Мы уже смотрели коэффициент корреляции между этими переменными (r = `r round(cor(zo$n_words, zo$n), 2)`).

Представим, что я перешел к новой системе координат:

```{r, fig.height=6, echo=FALSE, warning=FALSE}
zo %>% 
  select(n, n_words) %>% 
  prcomp() %>% 
  broom::augment(zo) %>% 
  mutate(titles = fct_reorder(titles, .fittedPC1)) %>% 
  ggplot(aes(.fittedPC1, titles, label = titles))+
  geom_point()
```

Теперь я могу предсказывать значения переменных `количество слов в рассказе` и `количестов и в рассказе` на основе этой новой переменной.

```{r}
zo %>% 
  select(n, n_words) %>% 
  prcomp(scale. = TRUE) %>% 
  broom::augment(zo) %>% 
  pivot_longer(names_to = "type", values_to = "value", n:n_words) %>% 
  mutate(type = recode(type, n = "количество и", n_words = "количество слов")) %>% 
  group_by(type) %>% 
  mutate(cor = str_c("r = ",round(cor(.fittedPC1, value), 2)),
         max = max(value)- sd(value)) %>% 
  ggplot(aes(.fittedPC1, value))+
  geom_point()+
  geom_label(aes(label = cor, y = max), x = -1.5)+
  facet_wrap(~type, scales = "free")+
  labs(x = "новая переменная", y = "старые переменные")
```

## Многомерное шкалирование (MDS)

Многомерное шкалирование -- преобразование из многомерного пространства в n-мерное пространство (чаще всего смотрят на n равное 2), которое старается как можно меньше исказить **расстояния** между наблюдениями.

```{r}
iris %>% 
  select(-Species) %>% 
  dist() %>% 
  cmdscale() %>% 
  as_tibble() %>% 
  bind_cols(iris) %>% 
  ggplot(aes(V1, V2, color = Species))+
  geom_point()
```

Если по какой-то причине вы хотите использовать большую размерность итогового пространства, можно использовать аргумент `k` функции `cmdscale()` (по умолчанию он 2). Как видно из кода, я использовал функцию `dist()`, которую мы видели в предыдущем разделе: мы можем использовать любую другую матрицу расстояний, которую мы посчитаем (существует множество метрик расстояния, которые можно посмотреть в справке `?dist`). Давайте, например, посмотрим на многомерное шкалирование расстояний Левинштейна-Димерау между стопсловами русского языка:

```{r}
library(stringdist)
library(stopwords)

stringdistmatrix(stopwords("ru")) %>% 
  cmdscale() %>% 
  as_tibble() %>% 
  mutate(words = stopwords("ru")) %>% 
  ggplot(aes(V1, V2, label = words))+
  geom_text()
```

Как интерпретировать получившийся график? Часто мы не можем придать никакого значения получившимся осям, однако расстояния между точками на графике призвано отражать расстояние в многомерном пространстве. Так что, используя многомерное шкалирование

* можно обнаружить, есть ли кластеры в многомерных данных
* можно обнаружить, есть ли связь между наблюдениями, в том числе невыраженная переменными, которые есть в датасете. Например, из графика со стопсловами, видна "скрытая" переменная -- длина слова.

```{block, type = "rmdtask"}
[В датасет](https://raw.githubusercontent.com/agricolamz/DS_for_DH/master/data/chekhov_zoshenko.csv) записаны частотности некоторых слов в рассказах А. Чехова и М. Зощенко. Постройте многомерное шкалирование используя все переменные, и раскрасьте рассказы в зависимости от авторства. Делятся ли рассказы на кластеры? Как вы думаете почему?
```

```{r, include=FALSE}
df <- read_csv("https://raw.githubusercontent.com/agricolamz/DS_for_DH/master/data/chekhov_zoshenko.csv")

df %>% 
  select(-titles, -text_author) %>% 
  dist() %>% 
  cmdscale() %>% 
  as_tibble() %>% 
  bind_cols(df) %>% 
  ggplot(aes(V1, V2, color = text_author))+
  geom_point()
```

## Метод главных компонент (PCA)

Метод главных компонент -- преобразование из многомерного пространства в n-мерное пространство (чаще всего смотрят на n равное 2), которое старается как можно меньше исказить **корреляции** между переменными.

```{r}
library(broom)
iris %>% 
  select(-Species) %>%
  prcomp() %>% 
  augment(iris) %>% 
  ggplot(aes(.fittedPC1, .fittedPC2, color = Species))+
  geom_point()
```

В целом, эта картинка ничем не отличается от полученной нам в многомерном шкалировании (плсю-минус зеркальное отображение; так будет каждый раз, если при построении многомерного шкалирования использовано евклидово расстояние). 

Так как метод главных компонент старается сохранить как можно больше дисперсии из всех данных, в результате этот метод (да и многомерное шкалирование) очень чувствителен к дисперсии переменных. Это значит, что данный метод будет давать разные результаты в зависимости того, в метрах исследуемая переменная или в километрах. Чтобы предотвратить этот крен в сторону переменных с большей дисперсией, следует добавлять в функцию `prcomp()` аргумент `scale. = TRUE`, которые, соответственно нормализует переменные перед применением алгоритма:

```{r}
iris %>% 
  select(-Species) %>%
  prcomp(scale. = TRUE) %>% 
  augment(iris) %>% 
  ggplot(aes(.fittedPC1, .fittedPC2, color = Species))+
  geom_point()
```

В отличие от многомерного шкалирования, метод главных компонент позволяет также посмотреть на процент объясненной дисперсии:

```{r}
iris %>% 
  select(-Species) %>%
  prcomp(scale. = TRUE) %>% 
  summary()
```

Ученые (к счастью) не договорились относительно порога, начиная с которого процент объясненной дисперсии является хорошим. Я обычно радуюсь значением больше 0.7 (т. е. при переходе к новым осям мы выкинули всего 30% дисперсии).

Кроме того, благодаря методу главных компонент мы можем посмотреть на связь переменных. Давайте продемонстрируем это на частотности слов в евангелиях:

```{r}
gospels <- read_csv("https://raw.githubusercontent.com/agricolamz/2019_data_analysis_for_linguists/master/data/gospel_freq_words.csv")
gospels

PCA <- prcomp(gospels[,-1], scale. = TRUE)
row.names(PCA$x) <- gospels$word

library(ggfortify)
autoplot(PCA,
         shape = FALSE,
         loadings = TRUE,
         label = TRUE,
         loadings.label = TRUE)
```

Косинус угла между стрелочками соответствует коэффиценту корреляции между ними

```{r}
cor(gospels[,-1])
```

Мы точно так же можем работать не только с данными, но и с матрицей расстояния:

```{r}
st_words <- tibble(words = stopwords("ru"))

stringdistmatrix(st_words$words) %>% 
  prcomp(scale. = TRUE) %>% 
  augment(st_words) %>% 
  ggplot(aes(.fittedPC1, .fittedPC2, label = words))+
  geom_text()

stringdistmatrix(st_words$words) %>% 
  prcomp(scale. = TRUE) %>% 
  summary()
```

```{block, type = "rmdtask"}
[В датасет](https://raw.githubusercontent.com/agricolamz/DS_for_DH/master/data/chekhov_zoshenko.csv) записаны частотности некоторых слов в рассказах А. Чехова и М. Зощенко. Проведите анализ методом главных компонент и визуализируйте первые две компоненты, используя все переменные, и раскрасьте рассказы в зависимости от авторства.
```

```{r, echo=FALSE, message=FALSE}
df <- read_csv("https://raw.githubusercontent.com/agricolamz/DS_for_DH/master/data/chekhov_zoshenko.csv")

df %>% 
  select(-titles, -text_author) %>% 
  prcomp(scale. = TRUE) %>% 
  augment(df) %>% 
  ggplot(aes(.fittedPC1, .fittedPC2, color = text_author))+
  geom_point()+
  stat_ellipse()
```

```{block, type = "rmdtask"}
Посчитайте долю кумулятивной дисперсии, объясненной первыми двумя компонентами.
```

```{r, results="asis", echo=FALSE}
library(checkdown)
check_question("0.10", options = c("0.10", "0.20", "0.30", "0.40", "0.50"), alignment = TRUE)
```


## Множественный анализ соответствий

## Другие методы  уменьшения размерности

Существуют и другие методы уменьшения размерности:

* LDA (Linear Discriminant Analysis), DCA (Discriminant Correspondence Analysis)
* tSNE (t-Distributed Stochastic Neighbor Embedding)
* и другие...