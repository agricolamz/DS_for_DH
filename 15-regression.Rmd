---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Корреляция и регрессия

```{r, message=FALSE, echo = FALSE}
library(tidyverse)
theme_set(theme_bw())
```

## Дисперсия и стандартное отклонение

Дисперсия --- мера разброса значений наблюдений относительно среднего. 

$$\sigma^2_X = \frac{\sum_{i = 1}^n(x_i - \bar{x})^2}{n - 1},$$

где

* $x_1, ..., x_n$ --- наблюдения;
* $\bar{x}$ --- среднее всех наблюдений;
* $X$ --- вектор всех наблюдений;
* $n$ --- количество наблюдений.

Представим, что у нас есть следующие данные:

```{r, echo=FALSE}
set.seed(42)
df <- tibble(x = sort(rnorm(20, mean = 50, sd = 10)), 
             y = seq_along(x))
df %>% 
  ggplot(aes(x))+
  geom_point(y = 0)+
  ggrepel::geom_text_repel(aes(label = y), y = 0)+
  labs(x = "значение наблюдений x")
```

Тогда дисперсия --- это сумма квадратов расстояний от каждой точки до среднего выборки (пунктирная линия) разделенное на количество наблюдений - 1 (по духу эта мера --- обычное среднее, но если вас инетересует разница смещенной и несмещенной оценки дисперсии, см. [видео](https://youtu.be/Cn0skMJ2F3c)).

```{r, echo = FALSE}
df %>% 
  mutate(positive_negative = x > mean(x)) %>% 
  ggplot(aes(x, y))+
  geom_vline(aes(xintercept = mean(x)), linetype = 2)+
  geom_linerange(aes(xmin = x, 
                     xmax = mean(x), 
                     color = positive_negative),
                 show.legend = FALSE) + 
  annotate(geom = "text", x = 56, y = 1, label = "среднее x")+
  geom_point()+
  scale_y_continuous(breaks = df$y)+
  labs(y = "номер наблюдений x",
       x = "значение наблюдений x")
```

Для того чтобы было понятнее, что такое дисперсия, давайте рассмотрим несколько расспределений с одним и тем же средним, но разными дисперсиями:

```{r, echo=FALSE, message=FALSE}
set.seed(42)
map_dfr(1:5*5, function(x){
  tibble(x = rnorm(20, mean = 50, sd = sqrt(x)),
         var = round(var(x)))
}) %>% 
  group_by(var) %>% 
  mutate(x = x - mean(x)+50) %>% 
  ggplot(aes(x, factor(var)))+
  geom_point()+
  ggridges::geom_density_ridges(alpha = 0.2)+
  geom_vline(aes(xintercept = mean(x)), linetype = 2)+
  labs(x = "значение наблюдений",
       y = "дисперсия наблюдений")
```

В R дисперсию можно посчитать при помощи функции `var()`.

```{r}
set.seed(42)
x <- rnorm(20, mean = 50, sd = 10)
var(x)
```

Проверим, что функция выдает то же, что мы записали в формуле.

```{r}
var(x) == sum((x - mean(x))^2)/(length(x)-1)
```

Так как дисперсия является квадратом отклонения, то часто вместо нее используют стандартное отклонение $\sigma$ --- корень из дисперсии. В R ее можно посчитать при помощи функции `sd()`:

```{r}
sd(x)
sd(x) == sqrt(var(x))
```

## z-преобразование



## Ковариация

Ковариация --- эта мера ассоциации двух переменных.

$$cov(X, Y) = \frac{\sum_{i = 1}^n(x_i - \bar{x})(y_i-\bar{y})}{n - 1},$$

где

* $(x_1, y_1), ..., (x_n, y_n)$ --- пары наблюдений;
* $\bar{x}, \bar{y}$ --- средние наблюдений;
* $X, Y$ --- векторы всех наблюдений;
* $n$ --- количество наблюдений.

Представим, что у нас есть следующие данные:

```{r, echo=FALSE}
set.seed(42)
tibble(x = rnorm(30, mean = 50, sd = 10), 
       y = x + rnorm(30, sd = 10)) %>% 
  mutate(x = x - mean(x)+ 50,
         y = y - mean(y)+ 55) ->
  df

df %>% 
  ggplot(aes(x, y))+
  geom_point()
```

Тогда, согласно формуле, для каждой точки вычисляется следующая площадь (пуктирными линиями обозначены средние):

```{r, echo = FALSE}
df %>% 
  ggplot(aes(x, y))+
  geom_hline(aes(yintercept = mean(y)), linetype = 2)+
  geom_vline(aes(xintercept = mean(x)), linetype = 2)+
  geom_rect(aes(ymin = mean(y), ymax = y[which.max(x)], 
                xmin = mean(x), xmax = max(x)), 
            fill = "red", alpha = 0.01, show.legend = FALSE)+
  geom_text(aes(x = mean(x)+4), y = 26, label = "среднее x", alpha = 0.05)+
  geom_text(aes(y = mean(y)+2), x = 25, label = "среднее y", alpha = 0.05)+
  geom_point()
```

Если значения $x_i$ и $y_i$ какой-то точки либо оба больше, либо оба меньше средних $\bar{x}$ и $\bar{y}$, то получившееся произведение будет иметь знак `+`, если же наоборот --- знак `-`. На графике это показано цветом.

```{r, echo=FALSE}
df %>% 
  mutate(fill_color = (x > mean(x) & y > mean(y)) | (!x > mean(x) & !y > mean(y)),
         fill_color = !fill_color) %>% 
  ggplot(aes(x, y))+
  geom_rect(aes(xmin = mean(x), xmax = x, 
                ymin = mean(y), ymax = y, fill = fill_color, color = fill_color),
            alpha = 0.1, show.legend = FALSE)+
  geom_hline(aes(yintercept = mean(y)), linetype = 2)+
  geom_vline(aes(xintercept = mean(x)), linetype = 2)+
  geom_text(aes(x = mean(x)+4), y = 26, label = "среднее x", alpha = 0.05)+
  geom_text(aes(y = mean(y)+2), x = 25, label = "среднее y", alpha = 0.05)+
  geom_point()
```

Таким образом, если много красных прямоугольников, то значение суммы будет положительное и обозначать положительную связь (чем больше $x$, тем больше $y$), а если будет много синий прямоугольников, то значение суммы отрицательное и обозначать положительную связь (чем больше $x$, тем меньше $y$). Непосредственно значение ковариации не очень информативно, так как может достаточно сильно варьироваться от датасета к датасету.

В R ковариацию можно посчитать при помощи функции `cov()`.

```{r}
set.seed(42)
x <- rnorm(10, mean = 50, sd = 10)
y <-  x + rnorm(10, sd = 10)
cov(x, y)
cov(x, -y*2)
```

Как видно, простое умножение на два удвоило значение ковариации, что показывает, что непосредственно ковариацию использовать для сравнения разных датасетов не стоит.

Проверим, что функция выдает то же, что мы записали в формуле.

```{r}
cov(x, y) == sum((x-mean(x))*(y - mean(y)))/(length(x)-1)
```


## Корреляция

### Корреляция Пирсона

$$\rho_{X,Y} = \frac{cov(X, Y)}{\sigma_X\times\sigma_Y} = \frac{1}{n-1}\times\sum_{i = 1}^n\left(\frac{x_i-\bar{x}}{\sigma_X}\times\frac{y_i-\bar{y}}{\sigma_Y}\right),$$

где 

* $(x_1, y_1), ..., (x_n, y_n)$ --- пары наблюдений;
* $\bar{x}, \bar{y}$ --- средние наблюдений;
* $X, Y$ --- векторы всех наблюдений;
* $n$ --- количество наблюдений.

Последнее уравнение показывает, что коэффициент корреляции Пирсона можно представить как среднее (с поправкой) произведение $z$-нормализованных значений двух переменных.

```{r, echo=FALSE}
df %>% 
  mutate_all(scale) %>% 
  mutate(fill_color = (x > mean(x) & y > mean(y)) | (!x > mean(x) & !y > mean(y)),
         fill_color = !fill_color) %>% 
  ggplot(aes(x, y))+
  geom_rect(aes(xmin = mean(x), xmax = x, 
                ymin = mean(y), ymax = y, fill = fill_color, color = fill_color),
            alpha = 0.1, show.legend = FALSE)+
  geom_hline(aes(yintercept = mean(y)), linetype = 2)+
  geom_vline(aes(xintercept = mean(x)), linetype = 2)+
  geom_text(aes(x = mean(x)+0.8), y = -2, label = "нормализованное среднее x", alpha = 0.05)+
  geom_text(aes(y = mean(y)+0.1), x = -1.6, label = "нормализованное среднее y", alpha = 0.05)+
  geom_point()
```

Эта нормализация приводит к тому, что 

* значения корреляции имеют те же свойства знака коэффициента что и ковариация:
    * если коэффициент положительный (т. е. много красных прямоугольников) --- связь между переменными положительная (чем **больше** $x$, тем **больше** $y$), 
    * если коэффициент отрицательный (т. е. много синих прямоугольников) --- связь между переменными отрицательная (чем **больше** $x$, тем **меньше** $y$);
* значение корреляции имееет не зависимое от типа данных интеретация:
    * если модуль коэффициента близок к 1 или ему равен --- связь между переменными сильная,
    * если модуль коэффициента близок к 0 или ему равен --- связь между переменными слабая.

Для того чтобы было понятнее, что такое корреляция, давайте рассмотрим несколько расспределений с разными значениями корреляции:

```{r, message = FALSE, warning=FALSE, echo = FALSE}
set.seed(42)
map_dfr(c(-0.5, -0.75, -0.95, 0.5, 0.75, 0.95), function(i){
  MASS::mvrnorm(n=100, 
                mu=rep(50,2), 
                Sigma=matrix(i, nrow=2, ncol=2) + diag(2)*(1-i)) %>% 
    as_tibble() %>% 
    mutate(id = i) %>% 
    rename(x = V1,
           y = V2)}) %>% 
  group_by(id) %>% 
  mutate(cor = round(cor(x, y), 3)) %>%
  ggplot(aes(x, y))+
  geom_smooth(method = "lm", se = FALSE, color = "gray80")+
  geom_point()+
  facet_wrap(~cor, nrow = 2, scales = "free")+
  labs(x = "", y = "")
```

Как видно из этого графика, чем ближе модуль корреляции к 1, тем боллее компактно расположены точки, чем ближе к 0, тем более рассеяны значения. Достаточно легко научиться приблизительно оценивать коэфициент корреляции на глаз, поиграв 2--5 минут в игру [Guess the correlation](http://guessthecorrelation.com/).

В R коэффициент корреляции Пирсона можно посчитать при помощи функции `cor()`.

```{r}
set.seed(42)
x <- rnorm(15, mean = 50, sd = 10)
y <-  x + rnorm(15, sd = 10)
cor(x, y)
```

Проверим, что функция выдает то же, что мы записали в формуле.

```{r}
cor(x, y) == cov(x, y)/(sd(x)*sd(y))
cor(x, y) == sum(scale(x)*scale(y))/(length(x)-1)
```


### Ранговые корреляции Спирмана и Кендала

## Регрессионный анализ

https://antoinesoetewey.shinyapps.io/statistics-202/