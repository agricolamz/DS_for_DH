---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Корреляция и регрессия

```{r, message=FALSE, echo = FALSE}
library(tidyverse)
theme_set(theme_bw())
```

## Дисперсия и стандартное отклонение

**Дисперсия** --- мера разброса значений наблюдений относительно среднего. 

$$\sigma^2_X = \frac{\sum_{i = 1}^n(x_i - \bar{x})^2}{n - 1},$$

где

* $x_1, ..., x_n$ --- наблюдения;
* $\bar{x}$ --- среднее всех наблюдений;
* $X$ --- вектор всех наблюдений;
* $n$ --- количество наблюдений.

Представим, что у нас есть следующие данные:

```{r, echo=FALSE}
set.seed(42)
df <- tibble(x = sort(rnorm(20, mean = 50, sd = 10)), 
             y = seq_along(x))
df %>% 
  ggplot(aes(x))+
  geom_point(y = 0)+
  ggrepel::geom_text_repel(aes(label = y), y = 0)+
  labs(x = "значение наблюдений x")
```

Тогда дисперсия --- это сумма квадратов расстояний от каждой точки до среднего выборки (пунктирная линия) разделенное на количество наблюдений - 1 (по духу эта мера --- обычное среднее, но если вас инетересует разница смещенной и несмещенной оценки дисперсии, см. [видео](https://youtu.be/Cn0skMJ2F3c)).

```{r, echo = FALSE}
df %>% 
  mutate(positive_negative = x > mean(x)) %>% 
  ggplot(aes(x, y))+
  geom_vline(aes(xintercept = mean(x)), linetype = 2)+
  geom_linerange(aes(xmin = x, 
                     xmax = mean(x), 
                     color = positive_negative),
                 show.legend = FALSE) + 
  annotate(geom = "text", x = 56, y = 1, label = "среднее x")+
  geom_point()+
  scale_y_continuous(breaks = df$y)+
  labs(y = "номер наблюдений x",
       x = "значение наблюдений x")
```

Для того чтобы было понятнее, что такое дисперсия, давайте рассмотрим несколько расспределений с одним и тем же средним, но разными дисперсиями:

```{r, echo=FALSE, message=FALSE}
set.seed(42)
map_dfr(1:5*5, function(x){
  tibble(x = rnorm(20, mean = 50, sd = sqrt(x)),
         var = round(var(x)))
}) %>% 
  group_by(var) %>% 
  mutate(x = x - mean(x)+50) %>% 
  ggplot(aes(x, factor(var)))+
  geom_point()+
  ggridges::geom_density_ridges(alpha = 0.2)+
  geom_vline(aes(xintercept = mean(x)), linetype = 2)+
  labs(x = "значение наблюдений",
       y = "дисперсия наблюдений")
```

В R дисперсию можно посчитать при помощи функции `var()`.

```{r}
set.seed(42)
x <- rnorm(20, mean = 50, sd = 10)
var(x)
```

Проверим, что функция выдает то же, что мы записали в формуле.

```{r}
var(x) == sum((x - mean(x))^2)/(length(x)-1)
```

Так как дисперсия является квадратом отклонения, то часто вместо нее используют более интерпретируемое стандартное отклонение $\sigma$ --- корень из дисперсии. В R ее можно посчитать при помощи функции `sd()`:

```{r}
sd(x)
sd(x) == sqrt(var(x))
```

```{block, type = "rmdtask"}
Посчитайте дисперсию переменной `sleep_total` в датасете `msleep`, встроенный в `tidyverse`. Ответ округлите до двух знаков после запятой.
```

```{r, results='asis', echo = FALSE}
library(checkdown)
check_question(answer = round(var(msleep$sleep_total), 2))
```

```{block, type = "rmdtask"}
Посчитайте стандартное отклонение переменной `sleep_total` в датасете `msleep`, встроенный в `tidyverse`. Ответ округлите до двух знаков после запятой.
```

```{r, results='asis', echo = FALSE}
check_question(answer = round(sd(msleep$sleep_total), 2))
```

## z-преобразование

**z-преобразование** (еще используют термин **нормализация**) --- это способ представления данных в виде расстояний от среднего, измеряемых в стандартных отклонениях. Для того чтобы его получить, нужно из каждого наблюдения вычесть среднее и результат разделить на стандартное отклонение.

$$x_i = \frac{x_i - \bar{x}}{\sigma_X}$$

Если все наблюдения z-преобразовать, то получиться распределение с средним в 0 и стандартным отклонением 1 (или очень близко к ним).

```{r, echo = FALSE}
set.seed(42)
x <- rnorm(40, mean = 50, sd = 10)
tibble(x = x) %>% 
  mutate(scale = (x - mean(x))/sd(x)) %>% 
  pivot_longer(names_to = "type", values_to = "value", x:scale) %>% 
  mutate(type = ifelse(type == "scale", "нормализованные данные", "x")) %>% 
  group_by(type) %>% 
  mutate(mean = mean(value),
         sd = mean + sd(value)) %>% 
  ggplot(aes(value))+
  geom_vline(aes(xintercept = mean), linetype = 2)+
  geom_vline(aes(xintercept = sd), linetype = 4, color = "darkgreen")+
  geom_text(x = 68, y = 0.005, label = "ст.\n отклон.", alpha = 0.05, color = "darkgreen")+
  geom_text(x = 1.5, y = 0.05, label = "ст.\n отклон.", alpha = 0.05, color = "darkgreen")+
  geom_text(x = 42, y = 0.005, label = "среднее", alpha = 0.05)+
  geom_text(x = -0.6, y = 0.05, label = "среднее", alpha = 0.05)+
  geom_rug()+
  geom_density()+
  facet_wrap(~type, scale = "free")
```

Само по себе z-преобразование ничего особенного нам про данные не говорит. Однако это преобразование позволяет привести к "общему знаменателю" разные переменные. Т. е. это преобразование ничего нам не говорит про конкретный набор данных, но позволяет сравнивать разные наборы данных.

В R z-преобразование можно сделать при помощи функции `scale()`. Эта функция вовзращает матрицу, поэтому я использую индекс `[,1]`, чтобы результат был вектором.

```{r}
set.seed(42)
x <- rnorm(20, mean = 50, sd = 10)
scale(x)[,1]
```

Проверим, что функция выдает то же, что мы записали в формуле.

```{r}
scale(x)[,1] == (x-mean(x))/sd(x)
```

```{block, type = "rmdtask"}
Однаждый я заполучил градусник со шкалой Фаренгейта и целый год измерял температуру в Москве при помощи градусников с шкалой Фарингейта и Цельсия. [В датасет](https://raw.githubusercontent.com/agricolamz/DS_for_DH/master/data/moscow_average_temperature.csv) записаны средние значения для каждого месяца. Постройте график нормализованных и ненормализованных измерений. Что можно сказать про измерения, сделанные разными термометрами?
```

```{r, echo=FALSE, message=FALSE}
read_csv("https://raw.githubusercontent.com/agricolamz/DS_for_DH/master/data/moscow_average_temperature.csv") %>% 
  group_by(type) %>% 
  mutate(normalised = scale(non_normalised)) %>% 
  pivot_longer(names_to = "normalisation", values_to = "value", non_normalised:normalised) %>% 
  ggplot(aes(value, color = type))+
  geom_density()+
  geom_rug()+
  facet_wrap(~normalisation, scales = "free")
```


## Ковариация

**Ковариация** --- эта мера ассоциации двух переменных.

$$cov(X, Y) = \frac{\sum_{i = 1}^n(x_i - \bar{x})(y_i-\bar{y})}{n - 1},$$

где

* $(x_1, y_1), ..., (x_n, y_n)$ --- пары наблюдений;
* $\bar{x}, \bar{y}$ --- средние наблюдений;
* $X, Y$ --- векторы всех наблюдений;
* $n$ --- количество наблюдений.

Представим, что у нас есть следующие данные:

```{r, echo=FALSE}
set.seed(42)
tibble(x = rnorm(30, mean = 50, sd = 10), 
       y = x + rnorm(30, sd = 10)) %>% 
  mutate(x = x - mean(x)+ 50,
         y = y - mean(y)+ 55) ->
  df

df %>% 
  ggplot(aes(x, y))+
  geom_point()
```

Тогда, согласно формуле, для каждой точки вычисляется следующая площадь (пуктирными линиями обозначены средние):

```{r, echo = FALSE}
df %>% 
  ggplot(aes(x, y))+
  geom_hline(aes(yintercept = mean(y)), linetype = 2)+
  geom_vline(aes(xintercept = mean(x)), linetype = 2)+
  geom_rect(aes(ymin = mean(y), ymax = y[which.max(x)], 
                xmin = mean(x), xmax = max(x)), 
            fill = "red", alpha = 0.01, show.legend = FALSE)+
  geom_text(aes(x = mean(x)+4), y = 26, label = "среднее x", alpha = 0.05)+
  geom_text(aes(y = mean(y)+2), x = 25, label = "среднее y", alpha = 0.05)+
  geom_point()
```

Если значения $x_i$ и $y_i$ какой-то точки либо оба больше, либо оба меньше средних $\bar{x}$ и $\bar{y}$, то получившееся произведение будет иметь знак `+`, если же наоборот --- знак `-`. На графике это показано цветом.

```{r, echo=FALSE}
df %>% 
  mutate(fill_color = (x > mean(x) & y > mean(y)) | (!x > mean(x) & !y > mean(y)),
         fill_color = !fill_color) %>% 
  ggplot(aes(x, y))+
  geom_rect(aes(xmin = mean(x), xmax = x, 
                ymin = mean(y), ymax = y, fill = fill_color, color = fill_color),
            alpha = 0.1, show.legend = FALSE)+
  geom_hline(aes(yintercept = mean(y)), linetype = 2)+
  geom_vline(aes(xintercept = mean(x)), linetype = 2)+
  geom_text(aes(x = mean(x)+4), y = 26, label = "среднее x", alpha = 0.05)+
  geom_text(aes(y = mean(y)+2), x = 25, label = "среднее y", alpha = 0.05)+
  geom_point()
```

Таким образом, если много красных прямоугольников, то значение суммы будет положительное и обозначать положительную связь (чем больше $x$, тем больше $y$), а если будет много синий прямоугольников, то значение суммы отрицательное и обозначать положительную связь (чем больше $x$, тем меньше $y$). Непосредственно значение ковариации не очень информативно, так как может достаточно сильно варьироваться от датасета к датасету.

В R ковариацию можно посчитать при помощи функции `cov()`.

```{r}
set.seed(42)
x <- rnorm(10, mean = 50, sd = 10)
y <-  x + rnorm(10, sd = 10)
cov(x, y)
cov(x, -y*2)
```

Как видно, простое умножение на два удвоило значение ковариации, что показывает, что непосредственно ковариацию использовать для сравнения разных датасетов не стоит.

Проверим, что функция выдает то же, что мы записали в формуле.

```{r}
cov(x, y) == sum((x-mean(x))*(y - mean(y)))/(length(x)-1)
```


## Корреляция

**Корреляция** --- это мера ассоциации/связи двух числовых переменных. Помните, что бытовое применение этого термина к категориальным переменным (например, корреляция цвета глаз и успеваемость на занятиях по R) не имеет смысла с точки зрения статистики.

### Корреляция Пирсона

**Коэффициент корреляции Пирсона** --- базовый коэффициент ассоциации переменных, однако стоит помнить, что он дает неправильную оценку, если связь между переменными нелинейна.

$$\rho_{X,Y} = \frac{cov(X, Y)}{\sigma_X\times\sigma_Y} = \frac{1}{n-1}\times\sum_{i = 1}^n\left(\frac{x_i-\bar{x}}{\sigma_X}\times\frac{y_i-\bar{y}}{\sigma_Y}\right),$$

где 

* $(x_1, y_1), ..., (x_n, y_n)$ --- пары наблюдений;
* $\bar{x}, \bar{y}$ --- средние наблюдений;
* $X, Y$ --- векторы всех наблюдений;
* $n$ --- количество наблюдений.

Последнее уравнение показывает, что коэффициент корреляции Пирсона можно представить как среднее (с поправкой, поэтому $n-1$, а не $n$) произведение $z$-нормализованных значений двух переменных.

```{r, echo=FALSE}
df %>% 
  mutate_all(scale) %>% 
  mutate(fill_color = (x > mean(x) & y > mean(y)) | (!x > mean(x) & !y > mean(y)),
         fill_color = !fill_color) %>% 
  ggplot(aes(x, y))+
  geom_rect(aes(xmin = mean(x), xmax = x, 
                ymin = mean(y), ymax = y, fill = fill_color, color = fill_color),
            alpha = 0.1, show.legend = FALSE)+
  geom_hline(aes(yintercept = mean(y)), linetype = 2)+
  geom_vline(aes(xintercept = mean(x)), linetype = 2)+
  geom_text(aes(x = mean(x)+0.8), y = -2, label = "нормализованное среднее x", alpha = 0.05)+
  geom_text(aes(y = mean(y)+0.1), x = -1.6, label = "нормализованное среднее y", alpha = 0.05)+
  geom_point()
```

Эта нормализация приводит к тому, что 

* значения корреляции имеют те же свойства знака коэффициента что и ковариация:
    * если коэффициент положительный (т. е. много красных прямоугольников) --- связь между переменными положительная (чем **больше** $x$, тем **больше** $y$), 
    * если коэффициент отрицательный (т. е. много синих прямоугольников) --- связь между переменными отрицательная (чем **больше** $x$, тем **меньше** $y$);
* значение корреляции имееет не зависимое от типа данных интеретация:
    * если модуль коэффициента близок к 1 или ему равен --- связь между переменными сильная,
    * если модуль коэффициента близок к 0 или ему равен --- связь между переменными слабая.

Для того чтобы было понятнее, что такое корреляция, давайте рассмотрим несколько расспределений с разными значениями корреляции:

```{r, message = FALSE, warning=FALSE, echo = FALSE}
set.seed(42)
map_dfr(c(-0.5, -0.75, -0.95, 0.5, 0.75, 0.95), function(i){
  MASS::mvrnorm(n=100, 
                mu=rep(50,2), 
                Sigma=matrix(i, nrow=2, ncol=2) + diag(2)*(1-i)) %>% 
    as_tibble() %>% 
    mutate(id = i) %>% 
    rename(x = V1,
           y = V2)}) %>% 
  group_by(id) %>% 
  mutate(cor = round(cor(x, y), 3)) %>%
  ggplot(aes(x, y))+
  geom_smooth(method = "lm", se = FALSE, color = "gray80")+
  geom_point()+
  facet_wrap(~cor, nrow = 2, scales = "free")+
  labs(x = "", y = "")
```

Как видно из этого графика, чем ближе модуль корреляции к 1, тем боллее компактно расположены точки друг к другу, чем ближе к 0, тем более рассеяны значения. Достаточно легко научиться приблизительно оценивать коэфициент корреляции на глаз, поиграв 2--5 минут в игру "Угадай корреляцию" [здесь](http://guessthecorrelation.com/) или [здесь](https://cheng-dsdp.shinyapps.io/CorApp/).

В R коэффициент корреляции Пирсона можно посчитать при помощи функции `cor()`.

```{r}
set.seed(42)
x <- rnorm(15, mean = 50, sd = 10)
y <-  x + rnorm(15, sd = 10)
cor(x, y)
```

Проверим, что функция выдает то же, что мы записали в формуле.

```{r}
cor(x, y) == cov(x, y)/(sd(x)*sd(y))
cor(x, y) == sum(scale(x)*scale(y))/(length(x)-1)
```

### Ранговые корреляции Спирмана и Кендала

## Регрессионный анализ

https://antoinesoetewey.shinyapps.io/statistics-202/