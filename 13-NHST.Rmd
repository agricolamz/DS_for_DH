---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Проверка статистических гипотез

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
theme_set(theme_bw())
```

## О статистике

Статистика позволяет оценить какие-то стохастические процессы, которые происходят в мире. Центральное понятие статистики --- **генеральная совокупность**, множество всех элементов какой-либо группы, параметр которой мы хотим оценить:

* все жители РФ при оценке роста;
* все возможные тексты писателя (реальные и потенциальные) при оценке частоты встречаемости каких-либо элементов;
* все возможные курсы валют при попытке оценить курс валюты завтра;
* все страны при попытке оценить количество уникальных имен в странах мира
* и т. д.

Весь статистический анализ строится на основе **предположений о свойствах генеральной совокупности** и **некоторой выборки из генеральной совкупности**. Так если мы не можем взять всю генеральную совокупность и оценить ее параметр θ (средний рост, доля встречаемости гласных в текстах писателя и т. д.), то мы берем случайную выборку из генеральной совокупности и оцениваем параметр выборки θ̂ и делаем предположения о том, как параметр может быть устроен в генеральной совокупности. Если выборка, которой мы располагаем содержит в себе генеральную совокупность, то нужда оценить некоторый параметр казалось бы отпадает (в таком случае задача переходит в область теории вероятностей):

* Какая доля слов "не" в корпусе текстов Пушкина?

Однако бывают задачи, которые даже обладая генеральной совокупностью, можно переформулировать в статистические:

* Какая доля слов "не" будет в свежеобнаруженном тексте Пушкина длины $n$?
* Исследователь каждый год ездит на остров Суматра и обнаруживает каждый год несколько неизвестных науке видов ящериц. С каждый годом он обнаруживает неизвестные науке виды ящериц все реже и реже. Можем ли мы оценить сколько ящериц неизвестного вида исследователь найдет в этом году?

Существует несколько школ статистического анализа: фриквентистская и байесовская. Мы будем работать в рамках фриквентистской.

## Проверка нулевой гипотезы

Теперь мы обсудим стандартный трюк, который получил большую популярность в XX веке, и сейчас повсеместно продолжает использоваться. Этот трюк, к сожалению, помогает лишь показать, что что-то отличается, так что мы немножко переиначим наши задачи.

Представим себе, что я исследую героев Звездных войн. Я верю, что герои с именем на "B" встречаются в Звездных войнах с вероятностью 0.103. В новом фильме из 13 новых персонажей 4 имеют имя на "B", т. е. мы наблюдаем долю 0.31. Является ли разница межда наблюдениями 0.31 и ожиданиями 0.103 статистически значимой?

Создадим две гипотезы:

* $H_0$ --- (нулевая гипотеза) разница не является статистически значимой, т. е. наблюдаемые данные могут происходят из ожидаемого распределения.
* $H_1$ --- (альтернативная гипотеза) разница является статистически значимой, т. е. наблюдаемые данные не могут происходят из ожидаемого распределения.

Нулевая гипотеза --- это гипотеза, которую каждый исследователь хочет отвергнуть, и принять альтернативную. После применения статистического критерия (каждый критерий зависит от конкретного статистического теста, а выбор теста зависит от типа данных) исследователь считает вероятность наблюдать такой или более экстремальный результат, если верна нулевая гипотеза (**p-value, p-уровень значимости**):

```{r, echo=FALSE}
tibble(x = seq(0, 13),
       y = dbinom(x, size = 13, 0.103),
       z = ifelse(x %in% 4:13, TRUE, NA)) %>% 
  ggplot(aes(x, y, fill = z))+
  geom_col(show.legend = FALSE)
```

```{r}
sum(dbinom(4:13, size = 13, prob = 0.103))
```

Это же можно сделать при помощи следующей функции:

```{r}
binom.test(x = 4, n = 13, p = 0.103, alternative = "greater")
```

Дальше в разных науках принимают некоторое критическое значение (в большинстве случаев это 0.05), и если p-value меньше данного заветного значения, считается, что тогда разница является статистически значимой.

![If all else fails, use "significant at a p>0.05 level" and hope no one notices (https://xkcd.com/1478/)](https://imgs.xkcd.com/comics/p_values.png)

## Классификация статистических тестов

### Количество выборок

* Одновыборочные тесты (one-sample tests)

```{r, echo = FALSE, message=FALSE}
set.seed(42)
tibble(x = rnorm(100, mean = 80, sd = 10)) %>% 
  ggplot(aes(x)) +
  geom_dotplot()+
  geom_vline(xintercept = 55, linetype = 2, size = 2, color = "darkgreen")+
  scale_y_continuous(breaks = c())+
  labs(y = "")
```


* Двухвыборочные тесты (two-sample tests)

```{r, echo = FALSE, message=FALSE}
set.seed(42)
tibble(x = rnorm(100, mean = 80, sd = 10),
       y = rnorm(100, mean = 65, sd = 10)) %>% 
  pivot_longer(names_to = "dataset", values_to = "value", x:y) %>% 
  group_by(dataset) %>% 
  mutate(mean = mean(value)) %>% 
  ggplot(aes(value, fill = dataset)) +
  geom_dotplot(show.legend = FALSE, alpha = 0.8)+
  geom_vline(aes(xintercept = mean, color = dataset), linetype = 2, size = 2, show.legend = FALSE)+
  scale_y_continuous(breaks = c())+
  labs(y = "")
```

* многовыборочные тесты (multiple-sample tests)

```{r, echo = FALSE, message=FALSE}
set.seed(42)
tibble(x = rnorm(100, mean = 80, sd = 10),
       y = rnorm(100, mean = 65, sd = 8),
       z = rnorm(100, mean = 95, sd = 6)) %>% 
  pivot_longer(names_to = "dataset", values_to = "value", x:z) %>% 
  group_by(dataset) %>% 
  mutate(mean = mean(value)) %>% 
  ggplot(aes(value, fill = dataset)) +
  geom_dotplot(show.legend = FALSE, alpha = 0.8)+
  geom_vline(aes(xintercept = mean, color = dataset), linetype = 2, size = 2, show.legend = FALSE)+
  scale_y_continuous(breaks = c())+
  labs(y = "")
```

### Направление

* односторонние
```{r,echo=FALSE}
tibble(x = -10:110) %>% 
  ggplot(aes(x)) +
  stat_function(fun = dnorm, args = c(mean = 60, sd = 10))+
  stat_function(fun = dnorm, args = c(mean = 60, sd = 10), 
                geom = 'area', xlim = c(qnorm(0.95, 60, 10), 110), fill = 'lightblue')

tibble(x = -10:110) %>% 
  ggplot(aes(x)) +
  stat_function(fun = dnorm, args = c(mean = 60, sd = 10))+
  stat_function(fun = dnorm, args = c(mean = 60, sd = 10), 
                geom = 'area', xlim = c(-10, qnorm(0.05, 60, 10)), fill = 'lightblue')
```

* двусторонние

```{r,echo=FALSE}
tibble(x = -10:110) %>% 
  ggplot(aes(x)) +
  stat_function(fun = dnorm, args = c(mean = 60, sd = 10))+
  stat_function(fun = dnorm, args = c(mean = 60, sd = 10), 
                geom = 'area', xlim = c(-10, qnorm(0.025, 60, 10)), fill = 'lightblue') +
  stat_function(fun = dnorm, args = c(mean = 60, sd = 10), 
                geom = 'area', xlim = c(qnorm(0.975, 60, 10), 110), fill = 'lightblue') 
```


### Парные vs. непарные

* непарные --- если наблюдения в одной группе независимы друг от друга (мужчины vs. женщины, пожилые vs. молодые? и т. д.)
* парные --- если наблюдения имеют соответствия между собой (настроение до пары R и после, измерение температуры обычным и инфракрасным термометром, и т. п.)

### Параметрические vs. непараметрические

Некоторые тесты работают с предположениями об устройстве данных. В нашем случае данные предположения: нормальность распределения.

### Классификация тестов

| распределение  | тип группы           | # групп | тест                           |
|----------------|----------------------|:-------:|--------------------------------|
| категориальные | с заданным значением |    1    | биномиальный тест, χ²          |
| категориальные | независимые          |    2    | χ², тест Фишера, G-test (LL-score)                |
| категориальные | зависимые            |    2    | критерий Мак-Нимара            |
| нормальное     | с заданным значением |    1    | одновыборочный t-test          |
| нормальное     | независимые          |    2    | t-test для независимых выборок |
| нормальное     | зависимые            |    2    | парный t-test                  |
| не нормальное  | с заданным значением |    1    | критерий Уилкоксона            |
| не нормальное  | независимые          |    2    | критерий Манна-Уитни           |
| не нормальное  | зависимые            |    2    | критерий Уилкоксона            |

## Одновыборочные тесты

### Биномиальный тест

Мы уже обсудили биномиальный тест выше. В частотном словаре [Ляшевская Шаров 2009], созданном на базе корпуса объемом 92 млн. словоупотреблений, существительное *кенгуру* имеет абсолютную частотность 0.0000021, а предлог *к* --- 0.005389 (его вариант *ко* в расчет не берется). В некотором тексте длиной 61981 слов существительное кенгуру встречается 58 раз, а предлог к --- 254. Можем ли мы считать, что это обычный ничем не примечательный результат?

```{r}
# кенгуру
binom.test(x = 58, n = 61981, p = 0.0000021)
# к
binom.test(x = 254, n = 61981, p = 0.005389)
```


```{block, type = "rmdtask"}
Мы посчитали количество букв *а* в рассказе А. П. Чехова и получили 58 букв из рассказа длинной 699 букв (пробелы и латинские буквы выкинуты). Является ли этот результат неожиданным, если мы ожидали долю 0.08. Приведите значение p-value с точностью до 2 знаком после запятой.
```

```{r, echo = FALSE, results='asis'}
library(checkdown)
check_question(answer = round(binom.test(x = 58, n = 699, p = 0.08)$p.value, 2))
```

### Одновыборочный t-тест

Из статьи С. Степановой 2011 мы знаем, что носители русского языка в среднем говорят 5.31 слога в секунду со стандартным отклонением 1,93 (мужчины 5.46 слога в секунду со средним отклонением 2.02, женщины 5.23 слога в секунду со средним отклонением 1.84, дети 3.86 слога в секунду со средним отклонением 1.67). Мы опросили 30 носителей деревни N и выяснили, что средняя равна 7, а стандартное отклонение равно 2. Является ли данная разницастатистически значимой?

```{r, message=FALSE}
set.seed(42)
data <- rnorm(n = 30, mean = 7, sd = 2)
tibble(data) %>% 
  ggplot(aes(data))+
  geom_dotplot()+
  geom_vline(xintercept = mean(data), size = 2, linetype = 2)+
  geom_vline(xintercept = 5.31, size = 2, linetype = 2, color = "red")+
  annotate(geom = "text", x = 3, color = "red", y = 0.75, label = "среднее согласно\n[Степанова 2011]", size = 5)
```

```{r}
t.test(data, mu = 5.31)
```

```{block, type = "rmdtask"}
Создайте 30 нормально распределенных наблюдений со средним 6 и стандартным отклонением 2, используя `set.seed(42)` и сравните полученные данные с результатами Степановой. Является ли разница статистически значимой? Приведите значение p-value с точностью до 2 знаком после запятой.
```

```{r, echo = FALSE, results='asis'}
set.seed(42)
my_data <- rnorm(n = 30, mean = 6, sd = 2)
check_question(answer = round(t.test(my_data, mu = 5.31)$p.value, 2))
```

t-тест имеет несколько предположений относительно структуры данных:

* нормальность распределения данных 
* гомоскедостичность (гомогенность) дисперсии

### Тест Уилкоксона

Если данные не нормально распределено, обычно используют критерий Уилкоксона

```{r, message=FALSE}
set.seed(42)
data <- rlnorm(n = 30, mean = 1.8, sd = 0.1)
tibble(data) %>% 
  ggplot(aes(data))+
  geom_dotplot()+
  geom_vline(xintercept = mean(data), size = 2, linetype = 2)+
  geom_vline(xintercept = 5.31, size = 2, linetype = 2, color = "red")+
  annotate(geom = "text", x = 4.9, color = "red", y = 0.75, label = "среднее согласно\n[Степанова 2011]", size = 5)
wilcox.test(data, mu = 5.31)
```

## Двухвыборочные тесты

### Двухвыборочный t-тест

Логика двухвыборочного теста такая же как одновыборочного:

```{r, message=FALSE}
set.seed(42)
sample_1 <- rnorm(25, mean = 40, sd = 5)
sample_2 <- rnorm(25, mean = 50, sd = 4.5)

tibble(sample_1, sample_2) %>% 
  pivot_longer(names_to = "dataset", values_to = "values", sample_1:sample_2) %>% 
  group_by(dataset) %>% 
  mutate(mean = mean(values)) %>% 
  ggplot(aes(values, fill = dataset))+
  geom_dotplot(show.legend = FALSE)+
  geom_vline(aes(xintercept = mean, color = dataset), size = 2, linetype = 2, show.legend = FALSE)

t.test(sample_1, sample_2)
```

```{block, type = "rmdtask"}
В работе (Coretta 2017, https://goo.gl/NrfgJm) рассматривается отношения между длительностью гласного и придыхание согласного. Автор собрал данные 5 носителей исландского. Дальше он извлек длительность гласного, после которого были придыхательные и непридыхательные. Скачайте [данные](https://raw.githubusercontent.com/agricolamz/DS_for_DH/master/data/icelandic.csv) и Проверьте, правда ли, что гласные перед аспирированныем согласными статистикали значимо короче гласных после которых непридыхательные для носителя. В ответе приведите t-статистику c точностью до трех знаков после запятой.
```

### Двухвыборочный парный t-тест

```{r, message=FALSE}
set.seed(42)
sample_1 <- rnorm(25, mean = 40, sd = 5)
sample_2 <- sample_1 - rnorm(25, mean = 5)

tibble(sample_1, sample_2) %>% 
  pivot_longer(names_to = "dataset", values_to = "values", sample_1:sample_2) %>% 
  group_by(dataset) %>% 
  mutate(mean = mean(values)) %>% 
  ggplot(aes(values, fill = dataset))+
  geom_dotplot(show.legend = FALSE)+
  geom_vline(aes(xintercept = mean, color = dataset), size = 2, linetype = 2, show.legend = FALSE)

t.test(sample_1, sample_2, paired = TRUE)
```


### Критерий Манна-Уитни

Если данные не распределены нормально, тогда используется критерий Манна-Уитни (по английски его тоже называют Wilcoxon test).

```{r, message=FALSE}
set.seed(42)
data_1 <- rlnorm(n = 30, mean = 1.8, sd = 0.1)
data_2 <- rlnorm(n = 30, mean = 1.6, sd = 0.1)

tibble(data_1, data_2) %>% 
  pivot_longer(names_to = "dataset", values_to = "values", data_1:data_2) %>% 
  group_by(dataset) %>% 
  mutate(mean = mean(values)) %>% 
  ggplot(aes(values, fill = dataset))+
  geom_dotplot(show.legend = FALSE)+
  geom_vline(aes(xintercept = mean, color = dataset), size = 2, linetype = 2, show.legend = FALSE)

wilcox.test(data_1, data_2)
```

### Критерий χ², тест Фишера

Если мы хотим сравнить распределение категориальных переменных, то обычно строят таблицы сопряженности и используют критерий χ².

Например, из интервью с носителями одной деревни произвольным образом выбрали по пол часа и посчитали кол-во реализаций диалектных форм vs. недиалектных. В результате получилось что у женщин было 107 диалектных форм vs. 93 недиалектные, а у мужчин — 74 vs. 45. Значима ли зафиксированная разница?

```{r, message=FALSE}
dialect_forms <- read_csv("https://raw.githubusercontent.com/agricolamz/DS_for_DH/master/data/dialect_forms_fake.csv")

dialect_forms %>% 
  ggplot(aes(gender, fill = form))+
  geom_bar()

table(dialect_forms)
prop.table(table(dialect_forms))

chisq.test(table(dialect_forms))
```

Критерий χ² считают относительно наблюдаемых $f_o$ и ожидаемых  $f_e$ значений:

$$\chi^2 = \sum\frac{\left(f_0-f_e\right)^2}{f_e}$$

Считается, что критерий χ² не стоит применять, если хотя бы одно из **ожидаемых** значений меньше 5. Давайте посмотрим на ожидаемые наблюдения:

```{r}
chisq.test(table(dialect_forms))$expected
chisq.test(table(dialect_forms))$observed
```

Если одно из **ожидаемых** значений меньше 5, то следует использовать тест Фишера:

```{r}
fisher.test(table(dialect_forms))
```

Вообще таблицы сопряженности бывают разные, да и тестов куда больше см. [@lydersen09]

### Критерий Мак Немара

Во время диалектологической экспедиции от 20 информантов (10 мужчин, 10 женщин) были записаны списки слов. Получилось, что 13 информантов использовали в речи велярный фрикативный ɣ, а 22 — велярный стоп ɡ. Через 5 лет работали с теми же информантами и соотношение немного поменялось: 7 ɣ против 28 ɡ. Является ли
получившаяся разница статистически значимой? 

```{r, message=FALSE}
repeated_dialect_forms <- read_csv("https://raw.githubusercontent.com/agricolamz/DS_for_DH/master/data/dialect_forms_repeated_fake.csv")

table(repeated_dialect_forms)
prop.table(table(repeated_dialect_forms))

repeated_dialect_forms %>% 
  ggplot(aes(time, fill = feature))+
  geom_bar()

mcnemar.test(table(repeated_dialect_forms))
```

## Послесловие

P-value очень много ругают

* за то, что его очень часто понимают неправильно [@gigerenzer04], [@goodman08]
* за то, что само по себе p-value < 0.05 слабый довод [@sterne01], [@nuzzo14], [@wasserstein16]

> Q: Why do so many colleges and grad schools teach p = 0.05?

> A: Because that's still what the scientific community and journal editors use.

> Q: Why do so many people still use p = 0.05?

> A: Because that's what they were taught in college or grad school

  [@wasserstein16]

В связи с этим, сейчас можно наблюдать

* большое обсуждение p-value vs. доверительные интервалы
* все нарастающую популярность Байесовской статистики

## Рассказы Чехова и Зощенко

###

```{block, type = "rmdtask"}
[Рассказы Чехова](https://github.com/agricolamz/DS_for_DH/raw/master/data/tidy_chekhov.tsv) и [Зощенко](https://github.com/agricolamz/DS_for_DH/raw/master/data/tidy_zoshenko.csv) собраны в tidy формате. Постройте график. Узнайте долю, которую составляют слова c леммой *деньги* от всех слов рассказа и проведите статистический тесты, сравнивающие [доли слов с леммой *деньги*] с знечением 0.000512 из частотного словаря русского языка [Шаров, Ляшевская 2011].
```

```{r, echo=FALSE, message=FALSE, cache=TRUE}
chekhov <- read_tsv("https://github.com/agricolamz/DS_for_DH/raw/master/data/tidy_chekhov.tsv")
zoshenko <- read_tsv("https://github.com/agricolamz/DS_for_DH/raw/master/data/tidy_zoshenko.csv")

chekhov %>% 
  filter(str_detect(word, "деньг")) %>% 
  group_by(titles, n_words) %>% 
  summarise(n = sum(n)) %>% 
  mutate(ratio = n/n_words) %>% 
  t.test(x = .$ratio, mu = 0.000512, data = .) ->
  ch_money

zoshenko %>% 
  filter(str_detect(word, "деньг")) %>% 
  group_by(titles, n_words) %>% 
  summarise(n = sum(n)) %>% 
  mutate(ratio = n/n_words) %>% 
  t.test(x = .$ratio, mu = 0.000512, data = .) ->
  z_money

chekhov$author <- "Чехов"
zoshenko$author <- "Зощенко"

chekhov %>% 
  bind_rows(zoshenko) %>% 
  filter(str_detect(word, "деньг")) %>% 
  group_by(author, titles, n_words) %>% 
  summarise(n = sum(n)) %>% 
  mutate(ratio = n/n_words) %>% 
  ggplot(aes(author, ratio))+
  geom_violin()+
  scale_y_log10()+
  labs(x = "", y = "доля слов с леммой 'деньги' (лог шкала)")
```

* Приведите значение p-value для Чехова, округленное до 3 знаков после запятой:
```{r, results='asis', echo = FALSE}
library(checkdown)
check_question(round(ch_money$p.value, 3))
```

* Приведите значение t-статистики для Чехова, округленное до 3 знаков после запятой:
```{r, results='asis', echo = FALSE}
check_question(round(ch_money$statistic, 3))
```

* Приведите значение p-value для Зощенко, округленное до 3 знаков после запятой:
```{r, results='asis', echo = FALSE}
check_question(round(z_money$p.value, 3))
```

* Приведите значение t-статистики для Зощенко, округленное до 3 знаков после запятой:
```{r, results='asis', echo = FALSE}
check_question(round(z_money$statistic, 3))
```

###

```{block, type = "rmdtask"}
[Рассказы Чехова](https://github.com/agricolamz/DS_for_DH/raw/master/data/tidy_chekhov.tsv) и [Зощенко](https://github.com/agricolamz/DS_for_DH/raw/master/data/tidy_zoshenko.csv) собраны в tidy формате. Постройте график. Проведите статистический тест, проверяющий, действительно ли Зощенко писал более короткие рассказы чем Чехов.
```

```{r, echo=FALSE}
chekhov %>% 
  bind_rows(zoshenko) %>% 
  distinct(author, titles, n_words) ->
  novels
  
fit <- t.test(data = novels, n_words~author)
novels %>% 
  ggplot(aes(author, n_words))+
  geom_violin()+
  labs(x = "", y = "количество слов в рассказе")
```


* Приведите значение p-value, округленное до 3 знаков после запятой
```{r, echo=FALSE, results='asis'}
check_question(round(fit$p.value, 3))
```

* Приведите значение t-статистики, округленное до 3 знаков после запятой:
```{r, results='asis', echo = FALSE}
check_question(round(fit$statistic, 3))
```


###

```{block, type = "rmdtask"}
Посчитайте энтропию каждого рассказа, визуализируйте разницу между авторами и проведите статистический тест, который показывает, что энтропия в рассказах Зощенко выше.
```


```{r, echo=FALSE}
chekhov %>% 
  bind_rows(zoshenko) %>% 
  group_by(author, titles, n_words) %>% 
  mutate(ratio = n/n_words) %>% 
  summarise(entropy = -sum(ratio*log2(ratio))) ->
  entropy

en_test <- t.test(data = entropy, entropy~author)

entropy %>% 
  ggplot(aes(author, entropy))+
  geom_violin()
```

* Приведите название рассказа с минимальной энтропией
```{r, echo=FALSE, results='asis'}
check_question("Вывеска", options = c("Вывеска", "Крест", "Надул", "Библиография"), random_answer_order = TRUE)
```

* Приведите название рассказа с максимальной энтропией
```{r, echo=FALSE, results='asis'}
check_question("Черная магия", 
               options = c("Черная магия", "Великосветская История", "Монастырь", "Вор"), 
               random_answer_order = TRUE)
```

* Приведите значение p-value, округленное до 3 знаков после запятой
```{r, echo=FALSE, results='asis'}
check_question(round(en_test$p.value, 3))
```

* Приведите значение t-статистики, округленное до 3 знаков после запятой:
```{r, results='asis', echo = FALSE}
check_question(round(en_test$statistic, 3))
```


###

```{block, type = "rmdtask"}
Визуализируйте количество слов и энтропию каждого автора. Какие выводы можно сделать на основании полученого графика?
```

```{r, echo=FALSE}
chekhov %>% 
  bind_rows(zoshenko) %>% 
  group_by(author, titles, n_words) %>% 
  mutate(ratio = n/n_words) %>% 
  summarise(entropy = -sum(ratio*log2(ratio))) %>% 
  ggplot(aes(entropy, n_words, color = author))+
  geom_point()+
  labs(x = "энтропия", y = "количество слов")
```


## Obamacare
```{block, type = "rmdtask"}
В 2010 Б. Обама подписал закон о доступном здравоохранении. В [датасет](https://raw.githubusercontent.com/agricolamz/DS_for_DH/master/data/obamacare.csv) записаны данные о доле незастрахованных людей (в процентах) в каждом штате в 2010 и в 2015 годах (исходные данные [на kaggle](https://www.kaggle.com/hhs/health-insurance)). Нарисуйте график (я использовал `geom_linerange(aes(ymin = ..., ymax = ...))`) и проведите статистический тест, показывающий что произошло изменение.
```

```{r, echo=FALSE, message=FALSE, fig.height=6}
obamacare <- read_csv("https://raw.githubusercontent.com/agricolamz/DS_for_DH/master/data/obamacare.csv")

obamacare.test <- t.test(obamacare$uninsured_rate_2010, obamacare$uninsured_rate_2015, data = obamacare, paired = TRUE)

obamacare %>% 
  mutate(state = fct_reorder(state, uninsured_rate_2010-uninsured_rate_2015)) %>% 
  ggplot(aes(state))+
  geom_linerange(aes(ymin = uninsured_rate_2010,
                     ymax = uninsured_rate_2015))+
    geom_point(aes(y = uninsured_rate_2010),
               color = "tomato") +
      geom_point(aes(y = uninsured_rate_2015),
               color = "blue")+
  coord_flip()+
  labs(x = "", y = "", title = "Difference between in uninsured rate in 2010 (red) and 2015 (blue)")
```

* Приведите среднее значение разниц между годами
```{r, echo=FALSE, results='asis'}
check_question(round(obamacare.test$estimate, 3))
```


* Приведите значение p-value, округленное до 3 знаков после запятой
```{r, echo=FALSE, results='asis'}
check_question(round(obamacare.test$p.value, 3))
```

* Приведите значение t-статистики, округленное до 3 знаков после запятой:
```{r, results='asis', echo = FALSE}
check_question(round(obamacare.test$statistic, 3))
```
